[["index.html", "现代精算统计模型 👨‍🏫 欢迎 🤔 答疑 🗓️ 课程安排", " 现代精算统计模型 Modern Actuarial Models 2020-11-30 15:57:05 👨‍🏫 欢迎 《现代精算统计模型》主要讲述如何使用统计学习和机器学习算法，提升传统的精算统计模型或者解决新的精算问题。这门课主要参考瑞士精算师协会发布的“精算数据科学”，该教程的主要目的是“为精算师提供一个对数据科学全面且易懂的介绍”，该教程提供了多篇方法性文章并开源代码，这样“读者可以相对容易地把这些数据科学方法用在自己的数据上”。 我们建议大家仔细阅读以下文献，尝试并理解所有代码。此网站将作为该课程的辅助，为大家答疑，总结文献，并对文献中的方法做扩展。该网站由授课老师高光远和助教张玮钰管理，欢迎大家反馈意见到助教、微信群、或邮箱 guangyuan.gao@ruc.edu.cn。 🤔 答疑 我定期把同学们的普遍疑问在这里解答，欢迎提问！ 👉 随机种子数(2020/11/20) 输入RNGversion(\"3.5.0\"); set.seed(100)，使得你的随机种子数和paper的相同，模型结果相近。 👉 MAC OS, Linux, WIN (2020/11/16) 据观察，在MAC OS和Linux系统下安装keras成功的比例较高。WIN系统下，Python各个包的依赖以及和R包的匹配有一定的问题，今天是通过更换镜像源解决了R中无法加载tensorflow.keras模块的问题，推测是TUNA源中WIN包依赖关系没有及时更新。 为了解决镜像源更新延迟、或者tensorflow版本过低的问题，这里共享WIN下经测试的conda环境配置。下载该文档，从该文档所在文件夹启动命令行，使用命令conda env create --name &lt;env&gt; --file filename.yaml，安装该conda环境。在R中使用reticulate::use_condaenv(\"&lt;env&gt;\",required=T)关联该环境。 另外，可下载MAC OS系统下经测试的conda环境配置。可通过conda env create --name &lt;env&gt; --file filename.yaml安装。 👉 CASdatasets (2020/11/13) 源文件在http://cas.uqam.ca/，但下载速度很慢，我把它放在坚果云共享。下载后选择install from local archive file。 👉 微信群 (2020/11/08) 🗓️ 课程安排 以下安排为初步计划，根据大家的需求和背景，我们可能要花更多的时间在某些重要的方法及其在精算上的应用。 第10周： 准备工作。 第11周: 1 - French Motor Third-Party Liability Claims https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3164764 机动 2 - Inisghts from Inside Neural Networks https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3226852 3 - Nesting Classical Actuarial Models into Neural Networks https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3320525 第12周： 4 - On Boosting: Theory and Applications https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3402687 第13周： 5 - Unsupervised Learning: What is a Sports Car https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3439358 第14周： 6 - Lee and Carter go Machine Learning: Recurrent Neural Networks https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3441030 第15周： 7 - The Art of Natural Language Processing: Classical, Modern and Contemporary Approaches to Text Document Classification https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3547887 第16周： 8 - Peeking into the Black Box: An Actuarial Case Study for Interpretable Machine Learning https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3595944 第17周： 9 - Convolutional neural network case studies: (1) Anomalies in Mortality Rates (2) Image Recognition https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3656210 "],["intro.html", "简介", " 简介 保险公司为社会中某些不可预知的经济损失带来了保障。保险公司承担了被保险人的不确定经济损失的风险，被保险人获得了保障，保险公司获得了保费。 通常，保险公司需要在保单的保险期限开始时确定保费，即在保险损失还未发生时确定保费。由于这种定价方式，保险产品和一般消费产品的生产周期相反，服从逆生产周期。 因此，预测模型在保险产品的定价中有广泛的应用。 计算机技术的发展带来了计算速度的极大提升和存储能力的极大提高，可以看到当前很多领域的发展都和计算机技术的革新密切相关。 机器学习算法作为一种预测模型，给传统的精算回归模型带来了挑战和机遇。 机器学习算法的预测能力相较于传统回归模型更高; 机器学习算法的解释性比较差。 基于机器学习算法的定价模型有助于保险公司细分风险，精确定价，减少逆选择风险。 假设保险公司A在定价中没有考虑到某个重要的风险因子，即对于是否有该类风险的被保险人都收取相同保费；而保险公司B在定价中考虑到该风险因子。 保险公司B会凭借低保费吸引低风险客户，凭借高保费使得高风险客户留在保险公司A。 由于被保险人的选择效应，最终保险公司A收取的保费不足以支付被保险人的损失，或者难以获取预期的保险收益。 另一方面，保险公司承担着风险转移和风险共担的社会角色，过度的细分风险会造成风险个体化，使得保险公司的风险转移和共担的作用消失。 比如，基于被保险人的高风险特征，保险公司会收取极高的保费，使得被保险人的风险转移价值荡然无存，也没有购买保险的动力。 所以，保险公司需要平衡风险细分和风险共担，使得保险公司既可以避免逆选择，也能提供有效的风险转移的保险产品。 一般地，保险定价模型受到保险监管机构的严格约束，这些模型在应用到实际中时，必须满足一定的条件。这给机器学习算法在保险定价中的应用带来了很多阻碍。 在中国，保监会限定了商业车险保费的区间，随着商业车险费率改革，这个区间在不断扩大，保险公司的定价模型发挥的作用越来越大。 European Union’s General Data Protection Regulation (2018) 建立了algorithmic accountability of decision-making machine algorithms制度，该制度赋予了参与者对于机器学习算法背后逻辑的知情权。 总之，定价模型必须在一定程度上可以解释给被保险人、保险监管机构等。从被保险人和保险监管的角度出发，他们也希望产品定价和风险管理是建立在一个较透明的模型而不是一个黑盒子，这样有利于维护市场公平、保障被保险人的利益、检测重要风险因子、建立防范风险措施。 "],["pre.html", "1 准备工作 1.1 常用链接 1.2 克隆代码 1.3 R interface to Keras 1.4 R interface to Python 1.5 Python", " 1 准备工作 “工欲善其事，必先利其器。” 在以下步骤中，当你发现安装非常慢时，可以尝试4G网络，尝试VPN，尝试改变CRAN的镜像源，或尝试改变conda的镜像源。conda镜像源通过修改用户目录下的.condarc文件使用TUNA镜像源，但该镜像源可能有更新延迟。 1.1 常用链接 准备工作中常用的链接有 GitHub Git SSH key GitHub and RStudio Jupyter Notebook Anaconda Miniconda 常用Conda命令 TUNA镜像源 R interface to Tensorflow and Keras reticulate Tensorflow Pytorch 校级计算云 CUDA cuDNN 1.2 克隆代码 GitHub提供了大量开源代码，这门课的代码主要来自此链接。通常，使用GitHub开源代码最方便的是fork到自己GitHub账户下，然后clone到本地。具体而言，需要进行以下操作： 注册GitHub账户。 Fork此链接到自己账户下的新仓库,可重新命名为如Modern-Actuarial-Models或其他名称。 安装git。在命令窗口使用$ git config --global user.name \"Your Name\" 和 $ git config --global user.email \"youremail@yourdomain.com\" 配置git的用户名和邮箱分别为GitHub账户的用户名和邮箱。最后可使用$ git config --list查看配置信息。 (选做)在本地电脑创建ssh public key，并拷贝到GitHub中Setting下SSH and GPG keys。ssh public key一般保存在本人目录下的隐藏文件夹.ssh中，扩展名为.pub。详见链接。设立SSH可以避免后续push代码到云端时，每次都需要输入密码的麻烦 电脑连接手机4G热点。一般地，在手机4G网络下克隆的速度比较快。 在RStudio中创建新的项目，选择Version Control，然后Git，在Repository URL中输入你的GitHub中刚才fork的新仓库地址（在Code下能找到克隆地址，如果第4步完成可以选择SSH地址，如果第4步没完成必须选择HTTPS地址），输入文件夹名称，选择存放位置，点击create project，RStudio开始克隆GitHub上该仓库的所有内容。 此时，你在GitHub上仓库的内容全部克隆到了本地，且放在了一个R Project中。在该Project中，会多两个文件，.Rproj和.gitignore，第一个文件保存了Project的设置，第二文件告诉git在push本地文件到GitHub时哪些文件被忽略。 如果你修改了本地文件，可以通过R中内嵌的Git上传到GitHub（先commit再push），这样方便在不同电脑上同步文件。git是代码版本控制工具，在push之前，你可以比较和上个代码版本的差异。GitHub记录了你每次push的详细信息，且存放在本地文件夹.git中。同时，如果GitHub上代码有变化，你可以pull到本地。如果经常在不同电脑上使用本仓库，一般需要先pull成最新版本，然后再编辑修改，最后commit-push到GitHub。 (选做) 你可以建立新的branch，使自己的修改和源代码分开。具体操作可参考链接，或者参考账户建立时自动产生的getting-started仓库。 (选做) 你可以尝试Github Desktop或者Jupyter Lab（加载git extension）管理，但对于这门课，这两种方式不是最优。 理论上，GitHub上所有仓库都可以采用以上方法在RStudio中管理，当然，RStudio对于R代码仓库管理最有效，因为我们可以直接在RStudio中运行仓库中的代码。 1.3 R interface to Keras 这里主要说明keras包的安装和使用。Keras是tensorflow的API，在keras中建立的神经网络模型都由tensorflow训练。安装keras包主要是安装Python库tensorflow，并让R与之相关联。 1.3.1 R自动安装 最简单的安装方式如下： 使用install.packages(\"tensorflow\")安装所有相关的包，然后library(\"tensorflow\")。 install_tensorflow() 这时大概率会出现 No non-system installation of Python could be found. Would you like to download and install Miniconda? Miniconda is an open source environment management system for Python. See https://docs.conda.io/en/latest/miniconda.html for more details. Would you like to install Miniconda? [Y/n]: 虽然你可能已经有Anaconda和Python，但R没有“智能”地识别出来，这时仍建议你选Y，让R自己装一下自己能更好识别的Miniconda, 这个命令还会自动建立一个独立conda环境r-reticulate，并在其中装好tensorflow, keras等。 上步如果正常运行，结束后会自动重启R。这时你运行library(tensorflow)然后tf$constant(\"Hellow Tensorflow\")，如果没报错，那继续install_packages(\"keras\"),library(\"keras\")。 用以下代码验证安装成功 model &lt;- keras_model_sequential() %&gt;% layer_flatten(input_shape = c(28, 28)) %&gt;% layer_dense(units = 128, activation = &quot;relu&quot;) %&gt;% layer_dropout(0.2) %&gt;% layer_dense(10, activation = &quot;softmax&quot;) summary(model) 如果出现以下错误 错误: Installation of TensorFlow not found. Python environments searched for &#39;tensorflow&#39; package: C:\\Users\\...\\AppData\\Local\\r-miniconda\\envs\\r-reticulate\\python.exe You can install TensorFlow using the install_tensorflow() function. 这个错误通常是由于r-reticulate中tensorflow和其他包的依赖关系发生错误，或者tensorflow版本太低，你可以更换镜像源、使用conda/pip install调整该环境中的tensorflow版本和依赖关系。 更好的方式是在conda下安装好指定版本的tensorflow然后关联到R，或者用其他方式让R找到其他方式安装的tensorflow。这时，你先把之前失败的安装C:\\Users\\...\\AppData\\Local\\r-miniconda，这个文件夹完全删掉。然后参考以下安装步骤。 1.3.2 使用reticulate关联conda环境 下载并安装Anaconda或者Miniconda。 运行Anaconda Prompt或者Anaconda Powershell Prompt，在命令行输入conda create -n r-tensorflow tensorflow=2.1.0，conda会创建一个独立的r-tensorflow环境，并在其中安装tensorflow包。 继续在命令行运行conda activate r-tensorflow加载刚刚安装的环境，并pip install h5py pyyaml requests Pillow scipy在该环境下安装keras依赖的包。至此，R需要的tensorflow环境已经准备好，接下来让R关联此环境。 重启R，library(\"reticulate\")然后use_condaenv(\"r-tensorflow\",required=T),这时R就和上面建立的环境关联好。 library(\"keras“)。这里假设你已经装好tensorflow和keras包。 用以下代码验证安装成功 model &lt;- keras_model_sequential() %&gt;% layer_flatten(input_shape = c(28, 28)) %&gt;% layer_dense(units = 128, activation = &quot;relu&quot;) %&gt;% layer_dropout(0.2) %&gt;% layer_dense(10, activation = &quot;softmax&quot;) summary(model) 1.3.3 指定conda安装 下载并安装Anaconda或者Miniconda。 命令行输入which -a python，找到Anaconda中Python的路径记为anapy。 R中install_packages(\"tensorflow\")，然后 install_tensorflow(method = &quot;conda&quot;, conda = &quot;anapy&quot;, envname = &quot;r-tensorflow&quot;, version = &quot;2.1.0&quot;) 此命令会在conda下创建r-tensorflow的环境并装好tensorflow包。 install_packages(\"keras\"); library(\"keras\") 用以下代码验证安装成功 model &lt;- keras_model_sequential() %&gt;% layer_flatten(input_shape = c(28, 28)) %&gt;% layer_dense(units = 128, activation = &quot;relu&quot;) %&gt;% layer_dropout(0.2) %&gt;% layer_dense(10, activation = &quot;softmax&quot;) summary(model) 1.3.4 使用reticulate安装 重启R，library(\"reticulate\")。 options(timeout=300)，防止下载时间过长中断。 install_miniconda()，将会安装miniconda并创建一个r-reticulateconda环境。此环境为R默认调用的Python环境。 （重启R）library(\"tensorflow\"); install_tensorflow(version=\"2.1.0\")，将会在r-reticulate安装tensorflow。 install_packages(\"keras\"); library(\"keras\") 用以下代码验证安装成功 model &lt;- keras_model_sequential() %&gt;% layer_flatten(input_shape = c(28, 28)) %&gt;% layer_dense(units = 128, activation = &quot;relu&quot;) %&gt;% layer_dropout(0.2) %&gt;% layer_dense(10, activation = &quot;softmax&quot;) summary(model) 1.4 R interface to Python R包reticulate为tensorflow的依赖包，当你装tensorflow它也被自动安装。它可以建立R与Python的交互。 1.4.1 reticulate 常见命令 conda_list()列出已安装的conda环境 virtualenv_list()列出已存在的虚拟环境 use_python, use_condaenv, use_virtualenv可以指定与R关联的python。 py_config()可以查看当前Python关联信息。 很多时候，R会创建一个独立conda环境r-miniconda/envs/r-reticulate。 1.4.2 切换R关联的conda环境 根据需要，你可以切换R关联的conda环境。具体步骤为 重启R library(\"reticulate\") conda_list()列出可以关联的环境和路径。 use_condaenv(\"env-name\")。env-name为关联的conda环境。 py_config查看是否关联成功。 1.5 Python 一般在每个Python（Conda）环境都需要安装一个Jupyter Notebook (conda install notebook)。 1.5.1 Conda环境 Python（conda）环境建立比较简单，在使用reticulate关联conda环境我们已经建立过一个环境r-tensorflow。具体操作如下: 建立独立环境conda create -n env-name python=3.8 tensorflow=2.1.0 notebook。该命令会建立env-name的环境，并在其中安装python=3.8,tensorflow，notebook包及其依赖包。 激活环境conda activate env-name. cd 到你的工作目录。 启动jupyter notebook jupyter notebook。 如遇到缺少的包，在该环境env-name下使用conda install ***安装缺少的包。 1.5.2 常用的Conda命令 conda create -n env-name2 --clone env-name1:复制环境 conda env list：列出所有环境 conda deactivate：退出当前环境 conda remove -n env-name --all：删除环境env-name中的所有包 conda list -n env-name: 列出环境env-name所安装的包 conda clean -p：删除不使用的包 conda clean -t：删除下载的包 conda clean -a：删除所有不必要的包 pip freeze &gt; pip_pkg.txt, pip install -r pip_pkg.txt 保存当前环境PyPI包版本，从文件安装PyPI包（需同系统） conda env export &gt; conda_pkg.yaml, conda env export --name env_name &gt; conda_pkg.yaml, conda env create --name env-name2 --file conda_pkg.yaml 保存当前/env-name环境所有包，从文件安装所有包（需同系统） conda list --explicit &gt; spec-list.txt, conda create --name env-name2 --file spec-list.txt 保存当前环境Conda包下载地址，从文件安装Conda包（需同系统） conda list --export &gt; spec-list.txt, conda create --name env-name2 --file spec-list.txt 保存当前环境所有包（类似conda env export），从文件安装所有包（需同系统） 1.5.3 Tensorflow/Pytorch GPU version Tensorflow可以综合使用CPU和GPU进行计算，GPU的硬件结构适进行卷积运算，所以适于CNN，RNN等模型的求解。 你可以申请使用校级计算云或者使用学院计算云，它们的服务器都配置了GPU，并装好了可以使用GPU的Tensorflow或者Pytorch。使用校级计算云时，你通常只需要运行Jupyter Notebook就可以使用云端GPU进行计算。使用学院计算云时，你通常需要知道一些常用的Linux命令，你也可以安装Ubuntu来熟悉Linux系统。 校级计算云和学院计算云有专门的IT人员帮你解决如本页所示的大部分IT问题。 你的机器如果有GPU，可以按如下步骤让GPU发挥它的并行计算能力，关键点是让GPU型号、GPU驱动、CUDA版本、Tensorflow或Pytorch版本彼此匹配，且彼此“相连”。百度或者必应上有很多相关资料可以作为参考。 查看电脑GPU和驱动，以及支持的CUDA版本。 或者在终端执行以下命令：nvidia-smi，查看你的NVIDIA显卡驱动支持的CUDA版本。 查看各个Tensorflow版本，Pytorch版本对应的CUDA和cuDNN. 下载并安装正确版本的CUDA。注册、下载并安装正确版本的cuDNN 配置CUDA和cuDNN. 安装Tensorflow或者Pytorch. "],["french.html", "2 车险索赔频率预测 2.1 背景介绍 2.2 预测模型概述 2.3 特征工程 2.4 训练集-验证集-测试集 2.5 泊松偏差损失函数 2.6 泊松回归模型 2.7 泊松可加模型 2.8 泊松回归树 2.9 随机森林 2.10 泊松提升树 2.11 模型比较", " 2 车险索赔频率预测 “见多识广、随机应变” 2.1 背景介绍 车险数据量大，风险特征多，对车险数据分析时可以体现出机器学习算法的优势，即使用算法从大数据中挖掘有用信息、提取特征。 在精算中，常常使用车险保单数据和历史索赔数据进行风险分析、车险定价等。保单数据库是在承保的时候建立的，索赔数据库是在索赔发生时建立的，大部分保单没有发生索赔，所以它们不会在索赔数据库中体现。 保单数据库记录了车险的风险信息，包括： 驾驶员特征：年龄、性别、工作、婚姻、地址等 车辆特征：品牌、车座数、车龄、价格、马力等 保单信息：保单编号、承保日期、到期日期 奖惩系数 索赔数据库记录了保单的索赔信息，可以得到索赔次数\\(N\\)和每次的索赔金额\\(Y_l,l=1,\\ldots,N\\)。理论上，车险的纯保费为以下随机和的期望 \\[S=\\sum_{l=1}^N Y_l\\] 假设索赔次数\\(N\\)和索赔金额\\(Y_l\\)独立且\\(Y_l\\)服从独立同分布，则 \\[\\mathbf{E}(S)=\\mathbf{E}(N)\\times\\mathbf{E}(Y)\\] 所以，车险定价问题很多时候都转化为两个独立模型：索赔次数（频率）模型和索赔金额（强度）模型。对于索赔次数模型，通常假设因变量服从泊松分布，建立泊松回归模型，使用的数据量等于保单数；对于索赔金额模型，通常假设因变量服从伽马分布，建立伽马回归模型，使用的数据量等于发生索赔的保单数。通常，在数据量不大时，索赔金额模型的建立难于索赔次数模型，因为只有发生索赔的保单才能用于索赔金额模型的建立。 记第\\(i\\)个保单的风险信息为\\(x_i\\in\\mathcal{X}\\)，保险公司定价的目标就是找到两个（最优）回归方程（映射），使之尽可能准确地预测索赔频率和索赔强度: \\[\\lambda: \\mathcal{X}\\rightarrow \\mathbf{R}_+, ~~~ x \\mapsto \\lambda(x_i)\\] \\[\\mu: \\mathcal{X}\\rightarrow \\mathbf{R}_+, ~~~ x \\mapsto \\mu(x_i)\\] 这里，\\(\\lambda(x_i)\\)是对\\(N\\)的期望的估计，\\(\\mu(x_i)\\)是对\\(Y\\)的期望的估计。基于这两个模型，纯保费估计为\\(\\lambda(x_i)\\mu(x_i)\\)。 2.2 预测模型概述 如何得到一个好的预测模型呢？可以从两个方面考虑： 让风险信息空间\\(\\mathcal{X}\\)丰富，也称为特征工程，比如包含\\(x,x^2,\\ln x\\)、或者加入车联网信息。 让映射空间\\(\\lambda\\in{\\Lambda},\\mu\\in M\\)丰富，如GLM只包含线性效应、相加效应，映射空间较小，神经网络包含非线性效应、交互作用，映射空间较大。 当你选取了映射空间较小的GLM，通常需要进行仔细的特征工程，使得风险信息空间适于GLM；当你选取了映射空间较大的神经网络，通常不需要进行特别仔细的特征工程，神经网络可以自动进行特征工程，发掘风险信息中的有用特征。 对于传统的统计回归模型，GLM，GAM，MARS，我们使用极大似然方法在映射空间中找到最优的回归方程，在极大似然中使用的数据集称为学习集（learning data set）。为了防止过拟合，我们需要进行协变量选择，可以删掉不显著的协变量，也可以使用逐步回归、最优子集、LASSO等，判断标准为AIC等。 对于树模型，我们使用 recursive partitioning by binary splits 算法对风险空间进行划分，使得各子空间内的应变量差异最小，差异通常使用偏差损失（deviance loss）度量。为了防止过拟合，通常使用交叉验证对树的深度进行控制。树模型训练使用的数据为学习集。 树模型的扩展为bootstrap aggregation（bagging）和random forest。第一种算法是对每个bootstrap样本建立树模型，然后平均每个树模型的预测；第二种算法类似第一种，但在建立树模型时，要求只在某些随机选定的协变量上分支。这两种扩展都属于集成学习（ensemble learning）。 提升算法有多种不同形式，它的核心思想类似逐步回归，区别是每步回归中需要依据上步的预测结果调整各个样本的权重，让上步预测结果差的样本在下步回归中占的权重较大。通常，每步回归使用的模型比较简单，如深度为3的树模型。提升算法也属于集成学习，和前面不同是它的弱学习器不是独立的，而bagging和random forest的弱学习器是彼此独立的。 对于集成算法，通常需要调整弱学习器的结构参数，如树的深度，也要判断弱学习器的个数，这些称为tuning parameters，通常通过比较在验证集（validation）的损失进行调参，防止过拟合。弱学习器中的参数通过在训练集（training）上训练模型得到。训练集和验证集的并集为学习集。 前馈神经网络的输入神经元为风险信息，下一层神经元为上一层神经元的线性组合并通过激活函数的非线性变换，最后输出神经元为神经网络对因变量期望的预测，通过减小输出神经元与因变量观察值的差异，训练神经网络中的参数。神经网络含有非常多的参数，很难找到全局最优解，而且最优解必然造成过拟合，所以一般采用梯度下降法对参数进行迭代，使得训练集损失在每次迭代中都有下降趋势。通过比较验证集损失确定迭代次数和神经网络的结构参数，防止过拟合。 如何评价一个预测模型的好坏呢？通常用样本外损失（test error）评价。对于索赔频率，使用泊松偏差损失，对于索赔强度，使用伽马偏差损失，可以证明这两个损失函数和似然函数成负相关。其中，平均泊松偏差损失为： \\[\\mathcal{L}(\\mathbf{N},\\mathbf{\\hat{N}})=\\frac{2}{|\\mathbf{N}|}\\sum_{i}N_i\\left[\\frac{\\hat{N}_i}{N_i}-1-\\ln\\left(\\frac{\\hat{N}_i}{N_i}\\right)\\right]\\] Keras中定义的损失函数为 \\[\\tilde{\\mathcal{L}}(\\mathbf{N},\\mathbf{\\hat{N}})=\\frac{1}{|\\mathbf{N}|}\\sum_{i}\\left[\\hat{N}_i-N_i\\ln\\left(\\hat{N}_i\\right)\\right]\\] 2.3 特征工程 加载包。 rm(list=ls()) library(CASdatasets) # data # library(keras) # neural network library(data.table) # fread,fwrite library(glmnet) # lasso library(plyr) # ddply library(mgcv) # gam library(rpart) # tree # library(rpart.plot) library(Hmisc) # error bar # devtools::install_github(&#39;henckr/distRforest&#39;) # library(distRforest) library(gbm) # boosting data(freMTPL2freq) #data(freMTPL2sev) # textwidth&lt;-7.3 #inch # fwrite(freMTPL2freq,&quot;data/freMTPL2freq.txt&quot;) # freMTPL2freq&lt;-fread(&quot;data/freMTPL2freq_mac.txt&quot;) &#39;data.frame&#39;: 678013 obs. of 12 variables: $ IDpol : num 1 3 5 10 11 13 15 17 18 21 ... $ ClaimNb : &#39;table&#39; num [1:678013(1d)] 1 1 1 1 1 1 1 1 1 1 ... $ Exposure : num 0.1 0.77 0.75 0.09 0.84 0.52 0.45 0.27 0.71 0.15 ... $ VehPower : int 5 5 6 7 7 6 6 7 7 7 ... $ VehAge : int 0 0 2 0 0 2 2 0 0 0 ... $ DrivAge : int 55 55 52 46 46 38 38 33 33 41 ... $ BonusMalus: int 50 50 50 50 50 50 50 68 68 50 ... $ VehBrand : Factor w/ 11 levels &quot;B1&quot;,&quot;B10&quot;,&quot;B11&quot;,..: 4 4 4 4 4 4 4 4 4 4 ... $ VehGas : chr &quot;Regular&quot; &quot;Regular&quot; &quot;Diesel&quot; &quot;Diesel&quot; ... $ Area : Factor w/ 6 levels &quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,..: 4 4 2 2 2 5 5 3 3 2 ... $ Density : int 1217 1217 54 76 76 3003 3003 137 137 60 ... $ Region : Factor w/ 21 levels &quot;Alsace&quot;,&quot;Aquitaine&quot;,..: 21 21 18 2 2 16 16 13 13 17 ... 2.3.1 截断 减少outliers/influential points 的影响 需根据每个变量的分布确定在哪里截断 索赔次数在4截断 风险暴露在1截断 马力在9截断 车龄在20截断 年龄在90截断 奖惩系数在150截断 2.3.2 离散化 目的是为了刻画非线性效应 需画出协变量的边缘经验索赔频率判断 离散化马力、车龄、年龄 VehPowerFac, VehAgeFac，DrivAgeFac 2.3.3 设定基础水平 方便假设检验 设定含有最多风险暴露的水平为基准水平 2.3.4 协变量变形 目的是为了刻画非线性效应 考虑协变量分布，使之变形后近似服从对称分布 DriveAgeLn/2/3/4, DensityLn dat1 &lt;- freMTPL2freq # claim number dat1$ClaimNb &lt;- pmin(dat1$ClaimNb, 4) # exposure dat1$Exposure &lt;- pmin(dat1$Exposure, 1) # vehicle power dat1$VehPowerFac &lt;- as.factor(pmin(dat1$VehPower,9)) aggregate(dat1$Exposure,by=list(dat1$VehPowerFac),sum) dat1[,&quot;VehPowerFac&quot;] &lt;-relevel(dat1[,&quot;VehPowerFac&quot;], ref=&quot;6&quot;) # vehicle age dat1$VehAge &lt;- pmin(dat1$VehAge,20) VehAgeFac &lt;- cbind(c(0:110), c(1, rep(2,5), rep(3,5),rep(4,5), rep(5,5), rep(6,111-21))) dat1$VehAgeFac &lt;- as.factor(VehAgeFac[dat1$VehAge+1,2]) aggregate(dat1$Exposure,by=list(dat1$VehAgeFac),sum) dat1[,&quot;VehAgeFac&quot;] &lt;-relevel(dat1[,&quot;VehAgeFac&quot;], ref=&quot;2&quot;) # driver age dat1$DrivAge &lt;- pmin(dat1$DrivAge,90) DrivAgeFac &lt;- cbind(c(18:100), c(rep(1,21-18), rep(2,26-21), rep(3,31-26), rep(4,41-31), rep(5,51-41), rep(6,71-51), rep(7,101-71))) dat1$DrivAgeFac &lt;- as.factor(DrivAgeFac[dat1$DrivAge-17,2]) aggregate(dat1$Exposure,by=list(dat1$DrivAgeFac),sum) dat1[,&quot;DrivAgeFac&quot;] &lt;-relevel(dat1[,&quot;DrivAgeFac&quot;], ref=&quot;6&quot;) dat1$DrivAgeLn&lt;-log(dat1$DrivAge) dat1$DrivAge2&lt;-dat1$DrivAge^2 dat1$DrivAge3&lt;-dat1$DrivAge^3 dat1$DrivAge4&lt;-dat1$DrivAge^4 # bm dat1$BonusMalus &lt;- as.integer(pmin(dat1$BonusMalus, 150)) # vehicle brand dat1$VehBrand &lt;- factor(dat1$VehBrand) # consider VehGas as categorical aggregate(dat1$Exposure,by=list(dat1$VehBrand),sum) dat1[,&quot;VehBrand&quot;] &lt;-relevel(dat1[,&quot;VehBrand&quot;], ref=&quot;B1&quot;) # vehicle gas dat1$VehGas &lt;- factor(dat1$VehGas) # consider VehGas as categorical aggregate(dat1$Exposure,by=list(dat1$VehGas),sum) dat1[,&quot;VehGas&quot;] &lt;-relevel(dat1[,&quot;VehGas&quot;], ref=&quot;Regular&quot;) # area (related to density) dat1$Area &lt;- as.integer(dat1$Area) # density dat1$DensityLn &lt;- as.numeric(log(dat1$Density)) # region aggregate(dat1$Exposure,by=list(dat1$Region),sum)[order( aggregate(dat1$Exposure,by=list(dat1$Region),sum)$x),] dat1[,&quot;Region&quot;] &lt;-relevel(dat1[,&quot;Region&quot;], ref=&quot;Centre&quot;) str(dat1) # model matrix for GLM design_matrix&lt;- model.matrix( ~ ClaimNb + Exposure + VehPowerFac + VehAgeFac + DrivAge + DrivAgeLn + DrivAge2 + DrivAge3 + DrivAge4 + BonusMalus + VehBrand + VehGas + Area + DensityLn + Region, data=dat1)[,-1] # VehPower, VehAge as factor variables # design_matrix2&lt;- # model.matrix( ~ ClaimNb + Exposure + VehPower + VehAge + DrivAge + # BonusMalus + VehBrand + VehGas + Area + DensityLn + Region, data=dat1)[,-1] # VehPower, VehAge, and DrivAge as continuous variables # dim(design_matrix2) 2.4 训练集-验证集-测试集 比例为\\(0.6:0.2:0.2\\) 根据索赔次数分层抽样 经验索赔频率约为\\(10\\%\\) seed_split&lt;-11 # claim 0/1 proportions index_zero&lt;-which(dat1$ClaimNb==0) index_one&lt;-which(dat1$ClaimNb&gt;0) prop_zero&lt;-round(length(index_zero)/(length(index_one)+length(index_zero)),2) prop_zero prop_one&lt;-round(length(index_one)/(length(index_one)+length(index_zero)),2) prop_one # 0.6:0.2:0.2 size_valid&lt;-round(nrow(dat1)*0.2,0) size_test&lt;-size_valid size_train&lt;-nrow(dat1)-2*size_valid # stratified sampling set.seed(seed_split) index_train_0&lt;-sample(index_zero,size_train*prop_zero) index_train_1&lt;-sample(index_one, size_train-length(index_train_0)) index_train&lt;-union(index_train_0,index_train_1) length(index_train);size_train index_valid&lt;-c(sample(setdiff(index_zero,index_train_0),round(size_valid*prop_zero,0)), sample(setdiff(index_one,index_train_1),size_valid-round(size_valid*prop_zero,0))) length(index_valid);size_valid index_test&lt;-setdiff(union(index_zero,index_one),union(index_train,index_valid)) index_learn&lt;-union(index_train,index_valid) length(index_train);length(index_valid);length(index_test) # train-validation-test; learn-test dat1_train&lt;-dat1[index_train,] dat1_valid&lt;-dat1[index_valid,] dat1_test&lt;-dat1[index_test,] dat1_learn&lt;-dat1[index_learn,] sum(dat1_train$ClaimNb)/sum(dat1_train$Exposure) sum(dat1_valid$ClaimNb)/sum(dat1_valid$Exposure) sum(dat1_test$ClaimNb)/sum(dat1_test$Exposure) sum(dat1_learn$ClaimNb)/sum(dat1_learn$Exposure) # glm matrix matrix_train&lt;-design_matrix[index_train,] matrix_valid&lt;-design_matrix[index_valid,] matrix_test&lt;-design_matrix[index_test,] matrix_learn&lt;-design_matrix[index_learn,] # gbm matrix (learn) dat1_learn_gbm&lt;-dat1_learn[,c(&quot;ClaimNb&quot;, &quot;Exposure&quot;, &quot;VehPower&quot;, &quot;VehAge&quot;, &quot;DrivAge&quot;, &quot;BonusMalus&quot;, &quot;VehBrand&quot;, &quot;VehGas&quot;, &quot;Area&quot;, &quot;DensityLn&quot;, &quot;Region&quot;)] class(dat1_learn_gbm) train_pro&lt;-size_train/(size_train+size_valid) 2.5 泊松偏差损失函数 平均泊松偏差损失 \\[\\mathcal{L}(\\mathbf{N},\\mathbf{\\hat{N}})=\\frac{2}{|\\mathbf{N}|}\\sum_{i}N_i\\left[\\frac{\\hat{N}_i}{N_i}-1-\\ln\\left(\\frac{\\hat{N}_i}{N_i}\\right)\\right]\\] Keras定义平均泊松偏差损失为 \\[\\tilde{\\mathcal{L}}(\\mathbf{N},\\mathbf{\\hat{N}})=\\frac{1}{|\\mathbf{N}|}\\sum_{i}\\left[\\hat{N}_i-N_i\\ln\\left(\\hat{N}_i\\right)\\right]\\] 因为对于大部分保单，\\(N_i-N_i\\ln N_i\\approx0\\)，所以泊松偏差损失函数约为Keras定义的2倍（至少在一个量级）。 \\[\\mathcal{L}(\\mathbf{N},\\mathbf{\\hat{N}})\\approx2\\tilde{\\mathcal{L}}(\\mathbf{N},\\mathbf{\\hat{N}})\\] Poisson.Deviance &lt;- function(pred,obs) {200*(sum(pred)-sum(obs)+sum(log((obs/pred)^(obs))))/length(pred)} keras_poisson_dev&lt;-function(y_hat,y_true) {100*sum(y_hat-y_true*log(y_hat))/length(y_true)} f_keras&lt;-function(x) 100*(x-x*log(x)) f_keras(0.1);f_keras(0.2) # png(&quot;./plots/1/poi_dev.png&quot;) plot(seq(0.05,0.15,0.01),f_keras(seq(0.05,0.15,0.01)),type=&quot;l&quot;, xlab=&quot;frequency&quot;,ylab=&quot;approximated Poisson deviance&quot;,main=&quot;100(freq - freq * ln freq)&quot;) abline(v=0.1,lty=2);abline(h=f_keras((0.1)),lty=2) # dev.off() 2.6 泊松回归模型 使用极大似然方法在映射空间中找到最优的回归方程 在极大似然中使用的数据集称为学习集（learning data set）。 为了防止过拟合，我们需要进行协变量选择，可以删掉不显著的协变量，也可以使用逐步回归、最优子集、LASSO等，判断标准为AIC等。 同质模型 \\[\\mathbf{E}(N)=\\beta_0\\] 全模型 \\[\\ln \\mathbf{E}(N)=\\ln e + \\beta_0 + \\beta_{\\text{VehPowerFac}} + \\beta_{\\text{VehAgeFac}} \\\\ + \\beta_1\\text{DrivAge} + \\beta_2\\ln\\text{DrivAge} + \\beta_3\\text{DrivAge}^2 + \\beta_4\\text{DrivAge}^3 + \\beta_5\\text{DrivAge}^4 \\\\ \\beta_6\\text{BM} + \\beta_{\\text{VehBrand}} + \\beta_{\\text{VehGas}} + \\beta_7\\text{Area} + \\beta_8\\text{DensityLn} + \\beta_{\\text{Region}}\\] # homogeneous model d.glm0 &lt;- glm(ClaimNb ~ 1 + offset(log (Exposure)), data=data.frame(matrix_learn), family=poisson()) #summary(d.glm0) dat1_test$fitGLM0 &lt;- predict(d.glm0, newdata=data.frame(matrix_test), type=&quot;response&quot;) keras_poisson_dev(dat1_test$fitGLM0,matrix_test[,1]) Poisson.Deviance(dat1_test$fitGLM0,matrix_test[,1]) # full GLM names(data.frame(matrix_learn)) {t1 &lt;- proc.time() d.glm1 &lt;- glm(ClaimNb ~ .-Exposure + offset(log(Exposure)), data=data.frame(matrix_learn), family=poisson()) (proc.time()-t1)} # summary(d.glm1) dat1_train$fitGLM1 &lt;- predict(d.glm1, newdata=data.frame(matrix_train), type=&quot;response&quot;) dat1_valid$fitGLM1 &lt;- predict(d.glm1, newdata=data.frame(matrix_valid), type=&quot;response&quot;) dat1_test$fitGLM1 &lt;- predict(d.glm1, newdata=data.frame(matrix_test), type=&quot;response&quot;) dat1_learn$fitGLM1 &lt;- predict(d.glm1, newdata=data.frame(matrix_learn), type=&quot;response&quot;) keras_poisson_dev(dat1_test$fitGLM1,matrix_test[,1]) Poisson.Deviance(dat1_test$fitGLM1,matrix_test[,1]) Step wise、LASSO协变量选择 逐步回归非常慢，在Linux 8核i7 3.4GHz 16G内存都需要50多分钟。且样本外损失和全模型没有明显减小。 5折CV Lasso在Linux 8核i7 3.4GHz 16G内存需要5分钟。 根据5折CV-error选取Lasso正则参数beta=4*10^-5。 两种方法的样本外损失和全模型没有明显减小，说明没有发生明显过拟合。也说明需要从非线性效应和交互项出发提升模型。 # step wise selection； this takes a long time (more than 50 minutes!) # d.glm00 &lt;- glm(ClaimNb ~ VehAgeFac1 + VehAgeFac3 + VehAgeFac4 + VehAgeFac5 + # DrivAge + DrivAge2 + DrivAge3 + DrivAge4 + DrivAgeLn + # BonusMalus + VehBrandB12 + VehGasDiesel + DensityLn + # offset(log (Exposure)), # data=data.frame(matrix_learn), family=poisson()) # {t1 &lt;- proc.time() # d.glm2&lt;-step(d.glm00,direction=&quot;forward&quot;,trace = 1, # scope =list(lower=formula(d.glm00), upper=formula(d.glm1))) # (proc.time()-t1)} d.glm2&lt;-glm(ClaimNb ~ VehAgeFac1 + VehAgeFac3 + VehAgeFac4 + VehAgeFac5 + DrivAge + DrivAge2 + DrivAge3 + DrivAge4 + DrivAgeLn + BonusMalus + VehBrandB12 + VehGasDiesel + DensityLn + VehPowerFac4 + VehPowerFac8 + RegionNord.Pas.de.Calais + VehPowerFac7 + RegionRhone.Alpes + RegionBretagne + RegionAuvergne + RegionLimousin + RegionLanguedoc.Roussillon + RegionIle.de.France + RegionAquitaine + RegionMidi.Pyrenees + RegionPays.de.la.Loire + RegionProvence.Alpes.Cotes.D.Azur + RegionPoitou.Charentes + RegionHaute.Normandie + VehBrandB5 + VehBrandB11 + RegionBasse.Normandie + VehBrandB14 + RegionCorse + offset(log(Exposure)), data=data.frame(matrix_learn), family=poisson()) summary(d.glm2) dat1_test$fitGLM2 &lt;- predict(d.glm2, newdata=data.frame(matrix_test), type=&quot;response&quot;) keras_poisson_dev(dat1_test$fitGLM2,data.frame(matrix_test)$ClaimNb) Poisson.Deviance(dat1_test$fitGLM2,matrix_test[,1]) # lasso regression； this takes a few minutes alpha0=1 # 1 for lasso, 0 for ridge. set.seed(7) # {t1 &lt;- proc.time() # cvfit = cv.glmnet(matrix_learn[,-c(1,2)], matrix_learn[,1], # family = &quot;poisson&quot;,offset=log(matrix_learn[,2]), # alpha = alpha0,nfolds = 5,trace.it = 1) # (proc.time()-t1)} # cvfit$lambda.min #4*10^-5 # cvfit$lambda.1se # 0.0016 # plot(cvfit) d.glm3 = glmnet(matrix_learn[,-c(1,2)], matrix_learn[,1], family = &quot;poisson&quot;, offset=log(matrix_learn[,2]), alpha=alpha0, lambda=4.024746e-05, trace.it = 1) dat1_test$fitLasso&lt;-predict(d.glm3, newx = matrix_test[,-c(1,2)], newoffset=log(matrix_test[,2]),type = &quot;response&quot;) keras_poisson_dev(dat1_test$fitLasso, matrix_test[,1]) Poisson.Deviance(dat1_test$fitLasso, matrix_test[,1]) 2.7 泊松可加模型 GAM边缘提升模型 样本外损失减少，说明非线性效应存在。 \\[\\ln \\mathbf{E}(N)=\\ln\\hat{\\lambda}^{\\text{GLM}}+s_1(\\text{VehAge})+s_2(\\text{BM})\\] \\(s_1,s_2\\)为样条平滑函数。 使用ddply聚合数据，找到充分统计量，加快模型拟合速度。 # GAM marginals improvement (VehAge and BonusMalus) {t1 &lt;- proc.time() dat.GAM &lt;- ddply(dat1_learn, .(VehAge, BonusMalus), summarise, fitGLM1=sum(fitGLM1), ClaimNb=sum(ClaimNb)) set.seed(1) d.gam &lt;- gam(ClaimNb ~ s(VehAge, bs=&quot;cr&quot;)+s(BonusMalus, bs=&quot;cr&quot;) + offset(log(fitGLM1)), data=dat.GAM, method=&quot;GCV.Cp&quot;, family=poisson) (proc.time()-t1)} summary(d.gam) dat1_train$fitGAM1 &lt;- predict(d.gam, newdata=dat1_train,type=&quot;response&quot;) dat1_valid$fitGAM1 &lt;- predict(d.gam, newdata=dat1_valid,type=&quot;response&quot;) dat1_test$fitGAM1 &lt;- predict(d.gam, newdata=dat1_test,type=&quot;response&quot;) keras_poisson_dev(dat1_test$fitGAM1, dat1_test$ClaimNb) Poisson.Deviance(dat1_test$fitGAM1,matrix_test[,1]) 2.8 泊松回归树 使用 recursive partitioning by binary splits 算法对风险空间进行划分，使得各子空间内的应变量差异最小。 为了防止过拟合，使用交叉验证确定cost-complexity parameter。 cp=10^-3.421(1-SD rule)剪枝成split=22的树，或者cp=10^-3.949(min CV rule)剪枝成split=55的树。 split=55(min CV rule)树的样本外损失较小。 Variable importance (min CV rule) BonusMalus VehAge VehBrand DrivAge VehGas VehPower Region DensityLn 4675.0231 4396.8667 1389.2909 877.9473 795.6308 715.3584 480.3459 140.5463 # cross validation using xval in rpart.control names(dat1_learn) set.seed(1) {t1 &lt;- proc.time() tree0&lt;-rpart(cbind(Exposure, ClaimNb) ~ VehPower + VehAge + DrivAge + BonusMalus + VehBrand + VehGas + Area + DensityLn + Region, data = dat1_learn, method = &quot;poisson&quot;, control = rpart.control (xval=5, minbucket=1000, cp=10^-5, maxcompete = 0, maxsurrogate = 0)) (proc.time()-t1)} x0 &lt;- log10(tree0$cptable[,1]) err0&lt;-tree0$cptable[,4] std0&lt;-tree0$cptable[,5] xmain &lt;- &quot;cross-validation error plot&quot; xlabel &lt;- &quot;cost-complexity parameter (log-scale)&quot; ylabel &lt;- &quot;relative CV error&quot; (cp_min&lt;-x0[which.min(err0)]) (cp_1sd&lt;-x0[min(which(err0&lt;min(err0)+std0[which.min(err0)]))]) (nsplit_min&lt;-tree0$cptable[which.min(err0),2]) (nsplit_1sd&lt;-tree0$cptable[min(which(err0&lt;min(err0)+std0[which.min(err0)])),2]) # png(&quot;./plots/1/tree_cv.png&quot;) errbar(x=x0, y=err0*100, yplus=(err0+std0)*100, yminus=(err0-std0)*100, xlim=rev(range(x0)), col=&quot;blue&quot;, main=xmain, ylab=ylabel, xlab=xlabel) lines(x=x0, y=err0*100, col=&quot;blue&quot;) abline(h=c(min(err0+std0)*100), lty=1, col=&quot;orange&quot;) abline(h=c(min(err0)*100), lty=1, col=&quot;magenta&quot;) abline(v=c(cp_1sd,cp_min),lty=2,col=c(&quot;orange&quot;,&quot;magenta&quot;)) legend(x=&quot;topright&quot;, col=c(&quot;blue&quot;, &quot;orange&quot;, &quot;magenta&quot;,&quot;orange&quot;,&quot;magenta&quot;), lty=c(1,1,1,2,2), lwd=c(1,1,1,1,1), pch=c(19,-1,-1,-1,-1), c(&quot;tree0&quot;, &quot;1-SD rule&quot;, &quot;min.CV rule&quot;, paste(&quot;log cp = &quot;,round(cp_1sd,3)),paste(&quot;log cp = &quot;, round(cp_min,3)))) # dev.off() tree1 &lt;- prune(tree0, cp=10^mean(cp_min,min(x0[x0&gt;cp_min]))) tree11&lt;- prune(tree0, cp=10^mean(cp_1sd,min(x0[x0&gt;cp_1sd]))) tree1$cptable[nrow(tree1$cptable),2];nsplit_min tree11$cptable[nrow(tree11$cptable),2];nsplit_1sd dat1_test$fitRT_min &lt;- predict(tree1, newdata=dat1_test)*dat1_test$Exposure dat1_test$fitRT_sd &lt;- predict(tree11, newdata=dat1_test)*dat1_test$Exposure keras_poisson_dev(dat1_test$fitRT_min, dat1_test$ClaimNb) keras_poisson_dev(dat1_test$fitRT_sd, dat1_test$ClaimNb) Poisson.Deviance(dat1_test$fitRT_min, dat1_test$ClaimNb) Poisson.Deviance(dat1_test$fitRT_sd, dat1_test$ClaimNb) tree1$variable.importance tree11$variable.importance 交叉验证可使用rpart(..., control=rpart.control(xval= ,...))或者xpred.rpart(tree, group)。 以上两种方式得到很相近的min CV rule剪枝树55 vs 51，但1-SD rule相差较多22 vs 12。 # K-fold cross-validation using xpred.rpart set.seed(1) {t1 &lt;- proc.time() tree00&lt;-rpart(cbind(Exposure, ClaimNb) ~ VehPower + VehAge + DrivAge + BonusMalus + VehBrand + VehGas + Area + DensityLn + Region, data = dat1_learn, method = &quot;poisson&quot;, control = rpart.control (xval=1, minbucket=1000 ,cp=10^-5, maxcompete = 0, maxsurrogate = 0)) (proc.time()-t1)} (n_subtrees &lt;- dim(tree00$cptable)[1]) std1&lt;- numeric(n_subtrees) err1 &lt;- numeric(n_subtrees) K &lt;- 5 xgroup &lt;- rep(1:K, length = nrow(dat1_learn)) xfit &lt;- xpred.rpart(tree00, xgroup) dim(xfit);dim(dat1_learn) for (i in 1:n_subtrees){ err_group&lt;-rep(NA,K) for (k in 1:K){ ind_group &lt;- which(xgroup ==k) err_group[k] &lt;- keras_poisson_dev(dat1_learn[ind_group,&quot;Exposure&quot;]*xfit[ind_group,i], dat1_learn[ind_group,&quot;ClaimNb&quot;]) } err1[i] &lt;- mean(err_group) std1[i] &lt;- sd(err_group) } x1 &lt;- log10(tree00$cptable[,1]) (cp_min1&lt;-x1[which.min(err1)]) (cp_1sd1&lt;-x1[min(which(err1&lt;min(err1)+std1[which.min(err1)]))]) (nsplit_min1&lt;-tree00$cptable[which.min(err1),2]) (nsplit_1sd1&lt;-tree00$cptable[min(which(err1&lt;min(err1)+std1[which.min(err1)])),2]) xmain &lt;- &quot;cross-validation error plot&quot; xlabel &lt;- &quot;cost-complexity parameter (log-scale)&quot; ylabel &lt;- &quot;CV error (in 10^(-2))&quot; errbar(x=x1, y=err1*100, yplus=(err1+std1)*100, yminus=(err1-std1)*100, xlim=rev(range(x1)), col=&quot;blue&quot;, main=xmain, ylab=ylabel, xlab=xlabel) lines(x=x1, y=err1*100, col=&quot;blue&quot;) abline(h=c(min(err1+std1)*100), lty=1, col=&quot;orange&quot;) abline(h=c(min(err1)*100), lty=1, col=&quot;magenta&quot;) abline(v=c(cp_1sd1,cp_min1),lty=2,col=c(&quot;orange&quot;,&quot;magenta&quot;)) legend(x=&quot;topright&quot;, col=c(&quot;blue&quot;, &quot;orange&quot;, &quot;magenta&quot;,&quot;orange&quot;,&quot;magenta&quot;), lty=c(1,1,1,2,2), lwd=c(1,1,1,1,1), pch=c(19,-1,-1,-1,-1), c(&quot;tree0&quot;, &quot;1-SD rule&quot;, &quot;min.CV rule&quot;, paste(&quot;log cp = &quot;,round(cp_1sd1,3)),paste(&quot;log cp = &quot;, round(cp_min1,3)))) tree2 &lt;- prune(tree00, cp=10^mean(cp_min1,min(x1[x1&gt;cp_min1]))) tree22 &lt;- prune(tree00, cp=10^mean(cp_1sd1,min(x1[x1&gt;cp_1sd1]))) printcp(tree2) printcp(tree22) dat1_test$fitRT2 &lt;- predict(tree2, newdata=dat1_test)*dat1_test$Exposure dat1_test$fitRT22 &lt;- predict(tree22, newdata=dat1_test)*dat1_test$Exposure keras_poisson_dev(dat1_test$fitRT2, dat1_test$ClaimNb) keras_poisson_dev(dat1_test$fitRT22, dat1_test$ClaimNb) Poisson.Deviance(dat1_test$fitRT2, dat1_test$ClaimNb) Poisson.Deviance(dat1_test$fitRT22, dat1_test$ClaimNb) sum((dat1_test$fitRT2-dat1_test$fitRT_min)^2) sum((dat1_test$fitRT22-dat1_test$fitRT_sd)^2) tree2$variable.importance tree1$variable.importance tree22$variable.importance tree11$variable.importance 2.9 随机森林 使用https://github.com/henckr/distRforest建立泊松随机森林。 ncand每次分裂考虑的协变量个数；subsample训练每棵树的样本。 使用验证损失确定树的数量。 # fit the random forest library(distRforest) ntrees0&lt;-200 set.seed(1) {t1 &lt;- proc.time() forest1&lt;-rforest(cbind(Exposure, ClaimNb) ~ VehPower + VehAge + DrivAge + BonusMalus + VehBrand + VehGas + Area + DensityLn + Region, data = dat1_train, method = &quot;poisson&quot;, control = rpart.control (xval=0, minbucket=1000 ,cp=10^-4, maxcompete = 0,maxsurrogate = 0, seed=1), parms=list(shrink=1), ncand=5,ntrees = ntrees0, subsample = 0.5, red_mem = T) (proc.time()-t1)} # determine number of trees using validation error fit_valid&lt;-rep(0,nrow(dat1_valid)) error_valid&lt;-rep(0,ntrees0) for (i in 1:ntrees0){ fit_valid&lt;-fit_valid + predict(forest1$trees[[i]], newdata=dat1_valid) * dat1_valid$Exposure fit_valid_norm &lt;- fit_valid/i error_valid[i]&lt;-Poisson.Deviance(fit_valid_norm, dat1_valid$ClaimNb) } # png(&quot;./plots/1/random_forest_error.png&quot;) plot(error_valid,type=&quot;l&quot;,xlab=&quot;number of trees&quot;,ylab=&quot;validation error in 10^-2&quot;) abline(v=which.min(error_valid),lty=2) # dev.off() (best.trees=which.min(error_valid)) # test error fitRF&lt;-rep(0,nrow(dat1_test)) for (i in 1:best.trees){ fitRF&lt;-fitRF+predict(forest1$trees[[i]], newdata=dat1_test)*dat1_test$Exposure } dat1_test$fitRF &lt;- fitRF/best.trees keras_poisson_dev(dat1_test$fitRF, dat1_test$ClaimNb) Poisson.Deviance(dat1_test$fitRF, dat1_test$ClaimNb) names(forest1$trees[[2]]$variable.importance) sum(forest1$trees[[3]]$variable.importance) 2.10 泊松提升树 n.trees 树的数量；shrinkage 学习步长，和树的数量成反比；interaction.depth 交互项深度；bag.fraction 每棵树使用的数据比例；train.fraction 训练集比例；n.minobsinnode叶子上最少样本量。 set.seed(1) {t1 &lt;- proc.time() gbm1 &lt;- gbm( ClaimNb ~ VehPower + VehAge + DrivAge + BonusMalus + VehBrand + VehGas + Area + DensityLn + Region + offset(log(Exposure)), data = dat1_learn_gbm, distribution = &quot;poisson&quot;, n.trees = 500, shrinkage = 0.1, interaction.depth = 5, bag.fraction = 0.5, train.fraction = train_pro, cv.folds = 0, n.minobsinnode = 1000, verbose = T ) (proc.time()-t1)} # plot the performance # png(&quot;./plots/1/gbm_error.png&quot;) gbm.perf(gbm1,method=&quot;test&quot;) legend(&quot;topright&quot;,lty=c(1,1,2),col=c(&quot;black&quot;,&quot;red&quot;,&quot;blue&quot;), c(&quot;training error&quot;, &quot;validation error&quot;, &quot;best iterations&quot;)) # dev.off() best.iter&lt;-gbm.perf(gbm1,method=&quot;test&quot;) dat1_test$fitGBM1&lt;- predict(gbm1, dat1_test,n.trees=best.iter,type=&quot;response&quot;)*dat1_test$Exposure keras_poisson_dev(dat1_test$fitGBM1,dat1_test$ClaimNb) Poisson.Deviance(dat1_test$fitGBM1,dat1_test$ClaimNb) 根据验证集损失确定迭代次数。 Variable importance rel.inf BonusMalus 27.687137 VehAge 19.976441 VehBrand 13.515198 Region 13.495375 DrivAge 9.284520 VehGas 7.082648 VehPower 4.583522 DensityLn 4.375159 Area 0.000000 重要变量的边缘效应 重要变量的交互效应 2.11 模型比较 ## model test_error test_error_keras ## 1 Intercept 33.5695 21.7647 ## 2 GLM 31.7731 20.8665 ## 3 GLM Lasso 31.8132 20.8866 ## 4 GAM 31.6651 20.8125 ## 5 Decision tree 30.9780 20.4690 ## 6 Random forest 30.9652 20.4626 ## 7 Generalized boosted model 30.8972 20.4286 ## 8 Neural network 31.0607 20.5080 Boosting &gt; RF &gt; Tree &gt; GAM &gt; GLM &gt; Homo "],["nn.html", "3 神经网络 3.1 建立神经网络的一般步骤 3.2 数据预处理 3.3 神经网络提升模型 （combined actuarial neural network） 3.4 神经网络结构 3.5 训练神经网络 3.6 总结 3.7 其它模型", " 3 神经网络 正如计算机速度的提升和MCMC方法给贝叶斯统计带来了生机，计算机运算能力的提升和反向传播算法（back propagation）也给神经网络带来了飞速发展。 Tensorflow和Pytorch的更新速度反映了这个领域的热度。 3.1 建立神经网络的一般步骤 3.1.1 明确目标和数据类型 神经网络是一种非参非线性回归模型，它可以刻画非线性效应和交互效应。 在使用神经网络前，需要理解研究目标和数据结构，有一些特殊的layer，如卷积层，专门为某种任务、或某种数据结构而设立，不是可以用在任何的数据上。 神经网络有大量的参数，全局最优解必然会造成过拟合，通常利用验证集损失来判断梯度下降的次数。 3.1.2 数据预处理 描述性统计分析 缺失值、异常值处理 连续型变量标准化，主要是为了让梯度下降法更有效地工作。常用的标准化方法有MinMaxScaler \\[x^*=2\\frac{x-\\min x}{\\max x - \\min x}-1\\] 分类变量，可以使用dummy coding、one-hot encoding，或者使用神经网络中的embedding layer。第三种办法可以有效地减少参数个数。 训练-验证-测试数据分割：训练集用于梯度下降法求解参数，验证集用于判断epoch次数、调整模型结构的超参数，测试集用于比较不同模型的样本外预测能力。 3.1.3 选取合适的神经网络类型 全连接神经网络：适用于一般的回归问题，如索赔频率预测。信息一直向前传递。参数个数较多。可解释性差。 卷积神经网络：适用于数据有空间结构，且相同的模式可能出现在不同的位置，如图像识别。信息一直向前传递。参数个数较少。有可解释性。 递归神经网络：适用于数据有时间序列特征，且相同的模式可能出现在不同时间点，如天气预报、语音识别。信息可以返回到前面的神经元。参数个数较多。可解释性差。 3.1.4 建立神经网络（全连接神经网络） 在建立神经网络时，需要考虑以下几点： 输入层数据类型 隐藏层层数，隐藏层性质，神经元个数，激活函数，正则化，dropout 输出神经元数据类型，输出神经元激活函数 损失函数选择 3.1.5 训练神经网络 在训练神经网络时，需要考虑以下几点 梯度下降法（optimizer） 迭代次数（patience） 遍历次数（epoch），批量大小（batch size） 3.1.6 调参 返回第4步，调整模型结构的超参数（hyper-parameter tuning），观察验证损失的变化，选取最终模型。 3.2 数据预处理 &#39;data.frame&#39;: 678013 obs. of 12 variables: $ IDpol : num 1 3 5 10 11 13 15 17 18 21 ... $ ClaimNb : &#39;table&#39; num [1:678013(1d)] 1 1 1 1 1 1 1 1 1 1 ... $ Exposure : num 0.1 0.77 0.75 0.09 0.84 0.52 0.45 0.27 0.71 0.15 ... $ VehPower : int 5 5 6 7 7 6 6 7 7 7 ... $ VehAge : int 0 0 2 0 0 2 2 0 0 0 ... $ DrivAge : int 55 55 52 46 46 38 38 33 33 41 ... $ BonusMalus: int 50 50 50 50 50 50 50 68 68 50 ... $ VehBrand : Factor w/ 11 levels &quot;B1&quot;,&quot;B10&quot;,&quot;B11&quot;,..: 4 4 4 4 4 4 4 4 4 4 ... $ VehGas : chr &quot;Regular&quot; &quot;Regular&quot; &quot;Diesel&quot; &quot;Diesel&quot; ... $ Area : Factor w/ 6 levels &quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,..: 4 4 2 2 2 5 5 3 3 2 ... $ Density : int 1217 1217 54 76 76 3003 3003 137 137 60 ... $ Region : Factor w/ 21 levels &quot;Alsace&quot;,&quot;Aquitaine&quot;,..: 21 21 18 2 2 16 16 13 13 17 ... 在进行下面code之前，需要运行上一章的代码直到Tree之前。 连续型变量：标准化处理。 PreProcess.Continuous &lt;- function(var1, dat1){ names(dat1)[names(dat1) == var1] &lt;- &quot;V1&quot; dat1$X &lt;- as.numeric(dat1$V1) dat1$X &lt;- 2*(dat1$X-min(dat1$X))/(max(dat1$X)-min(dat1$X))-1 names(dat1)[names(dat1) == &quot;V1&quot;] &lt;- var1 names(dat1)[names(dat1) == &quot;X&quot;] &lt;- paste(var1,&quot;X&quot;, sep=&quot;&quot;) dat1 } Features.PreProcess &lt;- function(dat1){ dat1$VehPower &lt;- pmin(dat1$VehPower,9) dat1 &lt;- PreProcess.Continuous(&quot;VehPower&quot;, dat1) dat1$VehAge &lt;- pmin(dat1$VehAge,20) dat1 &lt;- PreProcess.Continuous(&quot;VehAge&quot;, dat1) dat1$DrivAge &lt;- pmin(dat1$DrivAge,90) dat1 &lt;- PreProcess.Continuous(&quot;DrivAge&quot;, dat1) dat1$BonusMalus &lt;- pmin(dat1$BonusMalus,150) dat1 &lt;- PreProcess.Continuous(&quot;BonusMalus&quot;, dat1) dat1$VehBrandX &lt;- as.integer(dat1$VehBrand)-1 # categorical variable dat1$VehGas &lt;- as.factor(dat1$VehGas) dat1$VehGasX &lt;- as.integer(dat1$VehGas) - 1.5 # binary: continuous or categorical dat1 &lt;- PreProcess.Continuous(&quot;Area&quot;, dat1) dat1 &lt;- PreProcess.Continuous(&quot;Density&quot;, dat1) dat1$RegionX &lt;- as.integer(dat1$Region) - 1 # categorical dat1 } dat2 &lt;- Features.PreProcess(freMTPL2freq) names(dat2) dat2_train&lt;-dat2[index_train,] dat2_valid&lt;-dat2[index_valid,] dat2_test&lt;-dat2[index_test,] dat2_learn&lt;-dat2[index_learn,] 分类变量： 采用embedding layer。 训练集-验证集-测试集：分层抽样。 调整数据结构，使其匹配神经网络的输入层及其维度。输入数据集包括Xtrain, Brtain, Retrain, Vtrain，因变量数据集为Ytrain。 lambda.hom &lt;- sum(dat2_train$ClaimNb)/sum(dat2_train$Exposure);lambda.hom names(dat2) # index of continous variables (non-categorical) features &lt;- c(13:16, 18:20) names(dat2_learn)[features] (q0 &lt;- length(features)) # training data Xtrain&lt;- as.matrix(dat2_train[, features]) # design matrix learning sample Brtrain &lt;- as.matrix(dat2_train$VehBrandX) Retrain &lt;- as.matrix(dat2_train$RegionX) Ytrain&lt;- as.matrix(dat2_train$ClaimNb) Vtrain&lt;-as.matrix(log(dat2_train$Exposure*lambda.hom)) # validation data Xvalid&lt;- as.matrix(dat2_valid[, features]) # design matrix learning sample Brvalid &lt;- as.matrix(dat2_valid$VehBrandX) Revalid &lt;- as.matrix(dat2_valid$RegionX) Yvalid&lt;- as.matrix(dat2_valid$ClaimNb) Vvalid&lt;-as.matrix(log(dat2_valid$Exposure*lambda.hom)) xxvalid&lt;-list(Xvalid,Brvalid,Revalid,Vvalid) # testing data Xtest &lt;- as.matrix(dat2_test[, features]) # design matrix test sample Brtest &lt;- as.matrix(dat2_test$VehBrandX) Retest &lt;- as.matrix(dat2_test$RegionX) Ytest &lt;- as.matrix(dat2_test$ClaimNb) Vtest &lt;- as.matrix(log(dat2_test$Exposure*lambda.hom)) 3.3 神经网络提升模型 （combined actuarial neural network） 基本结构 \\[\\ln \\lambda(\\mathbf{x})= e\\hat{\\lambda}^{\\text{GAM}}(\\mathbf{x})\\hat{\\lambda}^{\\text{NN}}(\\mathbf{x})\\] 其中，\\(\\hat{\\lambda}^{\\text{GAM}}\\)为广义可加边缘提升模型的索赔频率估计值（参见上一章），\\(\\hat{\\lambda}^{\\text{NN}}\\)为神经网络索赔频率的估计值，第一项在模型训练中保持不变。 使用上述模型的优点： \\(\\hat{\\lambda}^{\\text{GAM}}\\)的部分可解释性。 神经网络从一个相对“较好”的初始状态\\(e\\hat{\\lambda}^{\\text{GAM}}(\\mathbf{x})\\)开始训练，很快收敛。 在代码实现中，可以把\\(e\\hat{\\lambda}^{\\text{GAM}}\\)当作伪风险暴露数。 CANN &lt;- 1 # 0 = normal NN, 1=CANN if (CANN==1){ Vtrain &lt;- as.matrix(log(dat1_train$fitGAM1)) Vvalid&lt;- as.matrix(log(dat1_valid$fitGAM1)) Vtest &lt;- as.matrix(log(dat1_test$fitGAM1)) } 3.4 神经网络结构 在构建神经网络时，需要注意以下几点： 3.4.1 结构参数 神经网络结构的超参数选择，BrLabel为车型个数，ReLabel为地区个数，q1-q4为四个隐藏层中神经元个数，d为embedding layer中神经元个数。 # hyperparameters of the neural network architecture (BrLabel &lt;- length(unique(dat2_train$VehBrandX))) (ReLabel &lt;- length(unique(dat2_train$RegionX))) q1 &lt;- 20 q2 &lt;- 15 q3 &lt;- 10 q4 &lt;- 5 d &lt;- 1 # dimensions embedding layers for categorical features 3.4.2 输入层 输入层包括Design, VehBrand, Region, LogVol，其中Design为连续型协变量的输入层，VehBrand, Region为分类变量的输入层，LogVol直接连接到模型输出神经元。 shape表示输入（输出）维度（神经元个数）,dtype表示数据类型，name表示层名。 shape=(None, 7) 中None表示样本大小，因为还没有数据进入神经网络，故此时不确定。 Tensor(“Design_1:0”, shape=(None, 7), dtype=float32) # input layer (Design &lt;- layer_input(shape = c(q0), dtype = &#39;float32&#39;, name = &#39;Design&#39;)) (VehBrand &lt;- layer_input(shape = c(1), dtype = &#39;int32&#39;, name = &#39;VehBrand&#39;)) (Region &lt;- layer_input(shape = c(1), dtype = &#39;int32&#39;, name = &#39;Region&#39;)) (LogVol &lt;- layer_input(shape = c(1), dtype = &#39;float32&#39;, name = &#39;LogVol&#39;)) 3.4.3 Embedding layer 建立一个layer，需要明确输入神经元个数input_dim和输出神经元个数output_dim，通常需要指定输出神经元个数，而输入神经元个数由它的上层输出神经元个数决定。 把分类变量用layer_embedding处理，这两个layer_embedding的输出神经元个数为\\(d\\)，即每个水平通过layer_embedding输出\\(d\\)个连续型变量，当\\(d=1\\)，layer_embedding类似于GLM对分类变量的处理。input_length主要用于时间序列数据，如每个样本为多个词组成的一句话，这里一个样本只有一个水平，故input_length = 1。 layer_flatten用于调整维度，layer_flatten的输入维度是\\(n\\times 1\\times d\\)，输出维度是\\(n\\times d\\)，该层没有参数。该输出维度是layer_dense要求的输入维度。建立神经网络需要注意层间维度匹配。 BrandEmb建立的映射为\\(\\{1,\\ldots,11\\}\\rightarrow 1\\times\\mathbf{R}^d\\rightarrow\\mathbf{R}^d\\). RegionEmb建立的映射为\\(\\{1,\\ldots,21\\}\\rightarrow 1\\times\\mathbf{R}^d\\rightarrow\\mathbf{R}^d\\) # embedding layer (BrandEmb = VehBrand %&gt;% layer_embedding(input_dim = BrLabel, output_dim = d, input_length = 1, name = &#39;BrandEmb&#39;) %&gt;% layer_flatten(name=&#39;Brand_flat&#39;)) # input_dim is the size of vocabulary; input_length is the length of input sequences (RegionEmb = Region %&gt;% layer_embedding(input_dim = ReLabel, output_dim = d, input_length = 1, name = &#39;RegionEmb&#39;) %&gt;% layer_flatten(name=&#39;Region_flat&#39;)) 3.4.4 隐藏层 9 Network建立的映射为\\[[-1,1]^{q0}\\times\\mathbf{R}^d\\times\\mathbf{R}^d\\rightarrow (-1,1)^{q1}\\rightarrow (-1,1)^{q2}\\\\ \\rightarrow (-1,1)^{q3}\\rightarrow (-1,1)^{q4}\\rightarrow\\mathbf{R}\\] layer_concatenate把三个输入层连起来，layer_dropout为防止过拟合，layer_batch_normalization为防止vanishing gradient problem，这三种层内无参数，且不会改变上层的维度。layer_dropout令一定比例的上层神经元为0，正则化方法还包括在layer_dense中使用\\(L^2\\)范数正则化kernel_regularizer = regularizer_l2。layer_batch_normalization把输出神经元映射到\\((-1,1)\\)，通常在激活函数为relu更有用。 常用的激活函数为tanh, relu, linear, exponential, softmax, sigmoid。其中，sigmoid, softmax适用于二分类和多分类的输出神经元，exponential适用于因变量为正，如此时的索赔频率预测。此外sigmoid和tanh有线性关系，可以只考虑其中一个。 layer_dense的映射为output = activation (dot (input, kernal) + bias)，所以每个输出神经元都含有输入神经元的信息。如果考虑多个全连接层，可以刻画协变量的交互效应现。激活函数如果取非线性函数，则可以刻画协变量的非线性效应。 Network中最后一层的参数设定为0，使得Network初始值为0，这样神经网络初始状态为GAM，梯度下降将从GAM开始。 Network = list(Design, BrandEmb, RegionEmb) %&gt;% layer_concatenate(name=&#39;concate&#39;) %&gt;% layer_dense(units=q1, activation=&#39;tanh&#39;, name=&#39;hidden1&#39;) %&gt;% layer_batch_normalization()%&gt;% layer_dropout(rate =0.05) %&gt;% layer_dense(units=q2, activation=&#39;tanh&#39;, name=&#39;hidden2&#39;) %&gt;% layer_batch_normalization()%&gt;% layer_dropout(rate =0.05) %&gt;% layer_dense(units=q3, activation=&#39;tanh&#39;, name=&#39;hidden3&#39;) %&gt;% layer_batch_normalization()%&gt;% layer_dropout(rate =0.05) %&gt;% layer_dense(units=q4, activation=&#39;tanh&#39;, name=&#39;hidden4&#39;) %&gt;% layer_batch_normalization()%&gt;% layer_dropout(rate =0.05) %&gt;% layer_dense(units=1, activation=&#39;linear&#39;, name=&#39;Network&#39;, weights = list(array(0, dim=c(q4,1)), array(0, dim=c(1)))) 3.4.5 输出层 Response建立的映射为\\(\\mathbf{R}\\times \\mathbf{R}\\rightarrow \\mathbf{R}^+\\)，且要求该映射中的参数不参加梯度下降法。可以看到Network的输出神经元为\\(\\ln \\hat{\\lambda}^{\\text{NN}}(\\mathbf{x})\\)，输入层LogVol为\\(\\ln e\\hat{\\lambda}^{\\text{GAM}}(\\mathbf{x})\\)，Response的输出神经元为\\[\\exp\\left(\\ln \\hat{\\lambda}^{\\text{NN}}(\\mathbf{x}) + \\ln e\\hat{\\lambda}^{\\text{GAM}}(\\mathbf{x})\\right)=e\\hat{\\lambda}^{\\text{GAM}}(\\mathbf{x})\\hat{\\lambda}^{\\text{NN}}(\\mathbf{x}).\\] 通过梯度下降法使得输出神经元\\(e\\hat{\\lambda}^{\\text{GAM}}(\\mathbf{x})\\hat{\\lambda}^{\\text{NN}}(\\mathbf{x})\\)与观察值\\(N\\)最接近（用泊松偏差损失度量），进而训练神经网络\\(\\hat{\\lambda}^{\\text{NN}}(\\mathbf{x})\\)中的参数。 Keras定义平均泊松偏差损失为 \\[\\tilde{\\mathcal{L}}(\\mathbf{N},\\mathbf{\\hat{N}})=\\frac{1}{|\\mathbf{N}|}\\sum_{i}\\left[\\hat{N}_i-N_i\\ln\\left(\\hat{N}_i\\right)\\right]\\] Response = list(Network, LogVol) %&gt;% layer_add(name=&#39;Add&#39;) %&gt;% layer_dense(units=1, activation=k_exp, name = &#39;Response&#39;, trainable=FALSE, weights=list(array(1, dim=c(1,1)), array(0, dim=c(1)))) model &lt;- keras_model(inputs = c(Design, VehBrand, Region, LogVol), outputs = c(Response)) model %&gt;% compile(optimizer = optimizer_nadam(), loss = &#39;poisson&#39;) summary(model) 下表列出了神经网络的结构，包括层的名称、(层的特性)、输出神经元个数、参数个数、上层的名称。 Model: &quot;model&quot; ________________________________________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================================================ VehBrand (InputLayer) [(None, 1)] 0 ________________________________________________________________________________________________________________________________ Region (InputLayer) [(None, 1)] 0 ________________________________________________________________________________________________________________________________ BrandEmb (Embedding) (None, 1, 1) 11 VehBrand[0][0] ________________________________________________________________________________________________________________________________ RegionEmb (Embedding) (None, 1, 1) 21 Region[0][0] ________________________________________________________________________________________________________________________________ Design (InputLayer) [(None, 7)] 0 ________________________________________________________________________________________________________________________________ Brand_flat (Flatten) (None, 1) 0 BrandEmb[0][0] ________________________________________________________________________________________________________________________________ Region_flat (Flatten) (None, 1) 0 RegionEmb[0][0] ________________________________________________________________________________________________________________________________ concate (Concatenate) (None, 9) 0 Design[0][0] Brand_flat[0][0] Region_flat[0][0] ________________________________________________________________________________________________________________________________ hidden1 (Dense) (None, 20) 200 concate[0][0] ________________________________________________________________________________________________________________________________ batch_normalization_1 (BatchNormalization (None, 20) 80 hidden1[0][0] ________________________________________________________________________________________________________________________________ dropout (Dropout) (None, 20) 0 batch_normalization_1[0][0] ________________________________________________________________________________________________________________________________ hidden2 (Dense) (None, 15) 315 dropout[0][0] ________________________________________________________________________________________________________________________________ batch_normalization_2 (BatchNormalization (None, 15) 60 hidden2[0][0] ________________________________________________________________________________________________________________________________ dropout_1 (Dropout) (None, 15) 0 batch_normalization_2[0][0] ________________________________________________________________________________________________________________________________ hidden3 (Dense) (None, 10) 160 dropout_1[0][0] ________________________________________________________________________________________________________________________________ batch_normalization_3 (BatchNormalization (None, 10) 40 hidden3[0][0] ________________________________________________________________________________________________________________________________ dropout_2 (Dropout) (None, 10) 0 batch_normalization_3[0][0] ________________________________________________________________________________________________________________________________ hidden4 (Dense) (None, 5) 55 dropout_2[0][0] ________________________________________________________________________________________________________________________________ batch_normalization_4 (BatchNormalization (None, 5) 20 hidden4[0][0] ________________________________________________________________________________________________________________________________ dropout_3 (Dropout) (None, 5) 0 batch_normalization_4[0][0] ________________________________________________________________________________________________________________________________ Network (Dense) (None, 1) 6 dropout_3[0][0] ________________________________________________________________________________________________________________________________ LogVol (InputLayer) [(None, 1)] 0 ________________________________________________________________________________________________________________________________ Add (Add) (None, 1) 0 Network[0][0] LogVol[0][0] ________________________________________________________________________________________________________________________________ Response (Dense) (None, 1) 2 Add[0][0] ================================================================================================================================ Total params: 970 Trainable params: 868 Non-trainable params: 102 ________________________________________________________________________________________________________________________________ 3.5 训练神经网络 训练神经网络需要注意以下几点： 初始化神经网络，将从GAM开始训练神经网络，且GAM预测部分保持不变。 当batch_size为全体训练集时，为steepest gradient decent method，参数在一个epoch只迭代一次。 当batch_size比全体训练集小时，为stochastic gradient decent method，参数在一个epoch迭代次数约为training size / batch size。 梯度下降法常引入momentum，进而提升优化效率，如adam, nadam,rmsprop等，这些算法自动选择learning rate, momentum parameters等。 callback_early_stopping (monitor = \"val_loss\", patience =10)表示如果验证集损失在10次内没有提升，那么停止训练，由此可以控制迭代次数。 使用predict在测试集上预测。 # fitting the neural network early_stop &lt;- callback_early_stopping(monitor = &quot;val_loss&quot;, patience =10) # print_dot_callback &lt;- callback_lambda( # on_epoch_end = function(epoch, logs) { # if (epoch %% 50 == 0) cat(&quot;\\n&quot;) # cat(&quot;.&quot;) # } # ) {t1 &lt;- proc.time(); fit &lt;- model %&gt;% fit(list(Xtrain, Brtrain, Retrain, Vtrain), Ytrain, epochs=500, batch_size=5000, verbose=1, validation_data=list(xxvalid,Yvalid), callbacks=list(early_stop)); (proc.time()-t1)} # png(&quot;./plots/1/nn.png&quot;) matplot(cbind(fit$metrics$loss,fit$metrics$val_loss), type=&quot;l&quot;,xlab=&quot;epoch&quot;,ylab=&quot;Keras Poisson Loss&quot;) legend(&quot;topright&quot;,c(&quot;training loss&quot;,&quot;validation loss&quot;),lty=c(1,2),col=1:2) # dev.off() # calculating the predictions dat2_test$fitNN &lt;- as.vector(model %&gt;% predict(list(Xtest, Brtest, Retest, Vtest))) keras_poisson_dev(dat2_test$fitNN, dat2_test$ClaimNb) Poisson.Deviance(dat2_test$fitNN, dat2_test$ClaimNb) 3.6 总结 dev_sum&lt;-fread(&quot;./plots/1/dev_sum.csv&quot;)[,-1] AD&lt;-data.frame(model=&quot;Neural network&quot;,test_error=0,test_error_keras=0) dev_sum&lt;-rbind(dev_sum,AD) dev_sum$test_error[8]&lt;-round(Poisson.Deviance(dat2_test$fitNN, dat2_test$ClaimNb),4) dev_sum$test_error_keras[8]&lt;-round(keras_poisson_dev(dat2_test$fitNN, dat2_test$ClaimNb),4) # write.csv(dev_sum,&quot;./plots/1/dev_sum.csv&quot;) Boosting &gt; RF &gt; Tree &gt; NN &gt; GAM &gt; GLM &gt; Homo Boosting, RF, Tree, NN相较于GAM的提升主要在于交互作用；GAM相较于GLM的提升不大，原因是在GLM中进行了合适的特征工程，可以刻画非线性效应。 3.7 其它模型 通过尝试发现，主要存在两个交互作用：VehPower, VehAge, VehGas, VehBrand和DriAge, BonusMalus，可设立如下简化的神经网络提升模型。 train.x &lt;- list(as.matrix(dat2_train[,c(&quot;VehPowerX&quot;, &quot;VehAgeX&quot;, &quot;VehGasX&quot;)]), as.matrix(dat2_train[,&quot;VehBrandX&quot;]), as.matrix(dat2_train[,c(&quot;DrivAgeX&quot;, &quot;BonusMalus&quot;)]), as.matrix(log(dat1_train$fitGAM1)) ) valid.x &lt;- list(as.matrix(dat2_valid[,c(&quot;VehPowerX&quot;, &quot;VehAgeX&quot;, &quot;VehGasX&quot;)]), as.matrix(dat2_valid[,&quot;VehBrandX&quot;]), as.matrix(dat2_valid[,c(&quot;DrivAgeX&quot;, &quot;BonusMalus&quot;)]), as.matrix(log(dat1_valid$fitGAM1)) ) test.x &lt;- list(as.matrix(dat2_test[,c(&quot;VehPowerX&quot;, &quot;VehAgeX&quot;, &quot;VehGasX&quot;)]), as.matrix(dat2_test[,&quot;VehBrandX&quot;]), as.matrix(dat2_test[,c(&quot;DrivAgeX&quot;, &quot;BonusMalus&quot;)]), as.matrix(log(dat1_test$fitGAM1)) ) neurons &lt;- c(15,10,5) model.2IA &lt;- function(Brlabel){ Cont1 &lt;- layer_input(shape = c(3), dtype = &#39;float32&#39;, name=&#39;Cont1&#39;) Cat1 &lt;- layer_input(shape = c(1), dtype = &#39;int32&#39;, name=&#39;Cat1&#39;) Cont2 &lt;- layer_input(shape = c(2), dtype = &#39;float32&#39;, name=&#39;Cont2&#39;) LogExposure &lt;- layer_input(shape = c(1), dtype = &#39;float32&#39;, name = &#39;LogExposure&#39;) x.input &lt;- c(Cont1, Cat1, Cont2, LogExposure) # Cat1_embed = Cat1 %&gt;% layer_embedding(input_dim = Brlabel, output_dim = 1, trainable=TRUE, input_length = 1, name = &#39;Cat1_embed&#39;) %&gt;% layer_flatten(name=&#39;Cat1_flat&#39;) # NNetwork1 = list(Cont1, Cat1_embed) %&gt;% layer_concatenate(name=&#39;cont&#39;) %&gt;% layer_dense(units=neurons[1], activation=&#39;relu&#39;, name=&#39;hidden1&#39;) %&gt;% layer_dense(units=neurons[2], activation=&#39;relu&#39;, name=&#39;hidden2&#39;) %&gt;% layer_dense(units=neurons[3], activation=&#39;relu&#39;, name=&#39;hidden3&#39;) %&gt;% layer_dense(units=1, activation=&#39;linear&#39;, name=&#39;NNetwork1&#39;, weights=list(array(0, dim=c(neurons[3],1)), array(0, dim=c(1)))) # NNetwork2 = Cont2 %&gt;% layer_dense(units=neurons[1], activation=&#39;relu&#39;, name=&#39;hidden4&#39;) %&gt;% layer_dense(units=neurons[2], activation=&#39;relu&#39;, name=&#39;hidden5&#39;) %&gt;% layer_dense(units=neurons[3], activation=&#39;relu&#39;, name=&#39;hidden6&#39;) %&gt;% layer_dense(units=1, activation=&#39;linear&#39;, name=&#39;NNetwork2&#39;, weights=list(array(0, dim=c(neurons[3],1)), array(0, dim=c(1)))) # NNoutput = list(NNetwork1, NNetwork2, LogExposure) %&gt;% layer_add(name=&#39;Add&#39;) %&gt;% layer_dense(units=1, activation=k_exp, name = &#39;NNoutput&#39;, trainable=FALSE, weights=list(array(c(1), dim=c(1,1)), array(0, dim=c(1)))) model &lt;- keras_model(inputs = x.input, outputs = c(NNoutput)) model %&gt;% compile(optimizer = optimizer_nadam(), loss = &#39;poisson&#39;) model } model &lt;- model.2IA(BrLabel) summary(model) early_stop &lt;- callback_early_stopping(monitor = &quot;val_loss&quot;, patience =10) # print_dot_callback &lt;- callback_lambda( # on_epoch_end = function(epoch, logs) { # if (epoch %% 50 == 0) cat(&quot;\\n&quot;) # cat(&quot;.&quot;) # } # ) # may take a couple of minutes if epochs is more than 100 {t1 &lt;- proc.time() fit &lt;- model %&gt;% fit(train.x, as.matrix(dat2_train$ClaimNb), epochs=500, batch_size=10000, verbose=1, validation_data=list(valid.x,dat2_valid$ClaimNb), callback=list(early_stop)) (proc.time()-t1)} matplot(cbind(fit$metrics$loss,fit$metrics$val_loss), type=&quot;l&quot;) dat2_test$fitGAMPlus &lt;- as.vector(model %&gt;% predict(test.x)) Poisson.Deviance(dat2_test$fitGAMPlus, dat2_test$ClaimNb) keras_poisson_dev(dat2_test$fitGAMPlus, dat2_test$ClaimNb) "],["boosting.html", "4 提升方法 (Boosting) 4.1 AdaBoost (0,1) 4.2 Logit Boost (real, discrete, gentle AdaBoost) 4.3 AdaBoost.M1 4.4 SAMME (Stage-wise Additive Modeling using a Multi-class Exponential loss function) 4.5 SAMME.R (multi-class real AdaBoost) 4.6 Gradient Boosting 4.7 Newton Boosting 4.8 XGBoost 4.9 Gradient Boost 4.10 XGBoost 4.11 Case study", " 4 提升方法 (Boosting) Breiman called AdaBoost the ‘best off-the-shelf classifier in the world’ (NIPS Workshop 1996). On the data science competition platform Kaggle, among 29 challenge winning solutions in 2015, 17 used XGBoost, a boosting algorithm introduced by Chen and Guestrin. AdaBoost是一种迭代算法，其核心思想是训练不同的分类器(弱分类器\\(T\\))，然后把这些弱分类器线性组合起来，构成一个更强的最终分类器（强分类器\\(C\\)）。 该算法是一个简单的弱分类算法提升过程，这个过程通过不断的训练，可以提高对数据的分类能力。整个过程如下所示： 通过对训练样本\\((\\mathcal{D},\\mathbb{\\omega})\\)的学习得到第\\(m-1\\)个弱分类器WeakClassifier m-1, \\(T^{(m-1)}\\)； 计算得出其分类错误率\\(\\epsilon^{(m-1)}\\)，以此计算出其弱分类器权重\\(\\alpha^{(m-1)}\\)与数据权重\\(\\omega^{(m-1)}_i\\); 用权重为\\(\\omega^{(m-1)}_i\\)的数据集训练得到训练弱分类器WeakClassifier m, \\(T^{(m)}\\); 重复以上不断迭代的过程; 最终结果通过加权投票表决的方法，让所有弱分类器\\(T^{(m)}\\)进行权重为\\(\\alpha^{(m)}\\)的投票表决的方法得到最终预测输出。 AdaBoost: Schapire and Freund (1997, 2012) LogitBoost: Friedman, Hastie, Tibshirani (1998) AdaBoost.M1: Schapire and Freund (1996, 1997) SAMME: Zhu, Zou, Rosset et al. (2006) SAMME.R: Zhu, Zou, Rosset et al. (2006) 4.1 AdaBoost (0,1) \\(Y\\in\\{0,1\\}\\) 初始权重 \\(\\omega^{(0)}_i=\\frac{1}{n}\\). 对于 \\(m=1,\\ldots,M\\), 重复以下2-5: 使用\\((\\mathcal{D},\\mathbf{\\omega}^{(m-1)})\\)，训练弱学习机\\(T^{(m-1)}\\). 计算加权分类错误 \\(\\epsilon^{(m-1)}=\\sum_{i=1}^n\\omega^{(m-1)}_i \\mathbb{I}(y_i \\neq T^{(m-1)}(\\mathbf{x}_i))\\). 计算模型权重 \\(\\alpha^{(m-1)}=\\ln\\beta^{(m-1)}\\), 其中\\(\\beta^{(m-1)}=\\frac{1-\\epsilon^{(m-1)}}{\\epsilon^{(m-1)}}\\). 计算样本权重\\(\\omega^{(m)}_i=\\omega^{(m-1)}_i\\exp\\left( \\alpha^{(m-1)}\\mathbb{I}(y_i \\neq T^{(m-1)}(\\mathbf{x}_i)) \\right)/w^{(m)}\\), 其中\\(w^{(m)}\\)为标准化常数。 最终预测结果为模型的权重之和较大的那个分类，即 \\[C(\\mathbf{x})= \\underset{k}{\\arg \\max} \\sum_{m=1}^M\\alpha^{(m)}\\mathbb{I}(T^{(m)}(\\mathbf{x})=k)\\]。 另外一种等价算法 \\(Y\\in\\{-1,1\\}\\) 初始权重 \\(D_1(i)=\\frac{1}{n}\\). 使用\\((\\mathcal{D},D_m)\\)，训练弱学习机\\(h_m\\). 计算加权分类错误\\(\\epsilon_m=D_m(i)\\mathbf{I}(Y_i\\neq h_m(\\mathbf{x}_i))\\). 计算模型权重\\(\\alpha_m=\\frac{1}{2}\\ln\\beta_m\\), 其中\\(\\beta_m=\\frac{\\epsilon_m}{1-\\epsilon_m}\\). 计算样本权重\\(D_{m+1}(i)=\\frac{D_m(i)}{Z_m}\\exp\\left(-\\alpha_mY_ih_m(\\mathbf{x_i})\\right)\\), 其中\\(Z_m\\)为标准化常数。 最终预测结果为\\(H(\\mathbf{x})= \\text{sign}\\left(\\sum_{m=1}^M \\alpha_mh_m(\\mathbf{x}) \\right)\\)。 4.2 Logit Boost (real, discrete, gentle AdaBoost) \\(Y\\in\\{-1,1\\}\\) 初始弱学习机 \\(H_0(\\mathbf)=h_0(\\mathbf{x})=0\\). 计算预测概率 \\(p_m(Y_i|\\mathbf{x_i})=\\frac{1}{1+\\exp(-Y_ih_{m-1}(\\mathbf{x_i}))}\\)。注：\\(p_m(Y_i=1|\\mathbf{x_i})+p_m(Y_i=-1|\\mathbf{x_i})=1\\) 计算样本权重 \\(D_m(i)=p_m(Y_i=y_i|\\mathbf{x_i})(1-p_m(Y_i=y_i|\\mathbf{x_i}))\\). 计算工作因变量 \\(Z_m(i) = y_i(1+\\exp(-y_i H_{m-1}(\\mathbf{x_i})))\\). 训练弱学习机\\(h_m\\)，使之最小化如下损失函数 \\[\\sum_{i=1}^N D_m(i)(h_m(\\mathbf{x_i})-Z_m(i))^2\\] 令\\(H_m=H_{m-1}+h_m\\) 最终预测结果为\\(\\Pr(Y=y|\\mathbf{x})= \\frac{1}{1+\\exp(-yH_M(\\mathbf{x_i}))}\\), 其中\\(H_M=h_0+\\ldots+h_M\\)。 4.3 AdaBoost.M1 \\(Y\\in\\{1,\\ldots,k\\}\\) 初始权重 \\(D_1(i)=\\frac{1}{n}\\). 使用\\((\\mathcal{D},D_m)\\)，训练弱学习机\\(h_m\\). 计算加权分类错误\\(\\epsilon_m=D_m(i)\\mathbf{I}(Y_i \\neq h_m(\\mathbf{x}_i)|\\). 计算模型权重\\(\\alpha_m=-\\ln\\beta_m\\), 其中\\(\\beta_m=\\frac{\\epsilon_m}{1-\\epsilon_m}\\). 计算样本权重\\(D_{m+1}(i)=\\frac{D_m(i)}{Z_m}\\beta_m^{1-\\mathbf{I}(Y_i \\neq h_m(\\mathbf{x}_i))}\\), 其中\\(Z_m\\)为标准化常数。 最终预测结果为 $H()= _{m:h_m()=y}_m $ 4.4 SAMME (Stage-wise Additive Modeling using a Multi-class Exponential loss function) \\(Y\\in \\{1,\\ldots,k\\}\\) 初始权重 \\(D_1(i)=\\frac{1}{n}\\). 使用\\((\\mathcal{D},D_m)\\)，训练弱学习机\\(h_m\\). 计算加权分类错误\\(\\epsilon_m=D_m(i)\\mathbf{I}(Y_i \\neq h_m(\\mathbf{x}_i)|\\). 计算模型权重\\(\\alpha_m=\\eta\\left(\\ln\\beta_m + \\ln(k-1) \\right)\\), 其中\\(\\beta_m=\\frac{\\epsilon_m}{1-\\epsilon_m}\\). 计算样本权重\\(D_{m+1}(i)=\\frac{D_m(i)}{Z_m}\\exp\\left(\\alpha_m\\mathbf{I}(Y_i \\neq h_m(\\mathbf{x}_i))\\right)\\), 其中\\(Z_m\\)为标准化常数。 最终预测结果为 $H()= _{m:h_m()=y}_m $ 4.5 SAMME.R (multi-class real AdaBoost) 4.6 Gradient Boosting 4.7 Newton Boosting 4.8 XGBoost 4.9 Gradient Boost 4.10 XGBoost 4.11 Case study 4.11.1 Commonly used Python code (for py-beginners) "]]
